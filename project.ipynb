{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valkucz/ib031/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O50hoEqQJMn4"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from yellowbrick.model_selection import ValidationCurve\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, make_scorer, mean_squared_error, ConfusionMatrixDisplay\n",
        "from sklearn.pipeline import make_pipeline, Pipeline, FeatureUnion\n",
        "from sklearn.compose import make_column_transformer, make_column_selector, ColumnTransformer\n",
        "from sklearn.impute import KNNImputer, SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, MinMaxScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "sns.set() \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijskxtdjka9F"
      },
      "source": [
        "## Explorační analýza\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0g9cVrcvx88"
      },
      "source": [
        "Dataset obsahuje medicinská data různých lidí. Dataset má 23 sloupců. Cílem je identifikovat riziko cukrovky. To představuje sloupec DIABETE3. Kromě toho dataset obsahuje sloupce popisující mentalní zdraví, fyzické zdraví, kuřácké návyky, či přístup k zdravotní péči. Data jsou zakódováná číselně a většinou se jedná o kategorická data. V rámci explorační analýzy bylo potřeba data částečně předspracovat, abychom získali použitelné výsledky z grafů."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "zo7yDsfbeVlS",
        "outputId": "d5a02bb6-640e-4745-d3d9-e631f4351558"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-53fb15061d90>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiabetes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./diabetes.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdiabetes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './diabetes.csv'"
          ]
        }
      ],
      "source": [
        "diabetes = pd.read_csv('./diabetes.csv', index_col=0)\n",
        "diabetes.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nd9QZNEdZgDP"
      },
      "outputs": [],
      "source": [
        "diabetes.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzaPI1If5_Hs"
      },
      "outputs": [],
      "source": [
        "diabetes.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o95x2WqVeVlU"
      },
      "outputs": [],
      "source": [
        "diabetes = diabetes.drop(columns=['ID'])\n",
        "\n",
        "train_set, test_set = train_test_split(diabetes, test_size=0.2, random_state=42)\n",
        "\n",
        "train_inputs, train_targets = train_set.loc[:, train_set.columns != 'DIABETE3'], train_set.loc[:,\n",
        "                                                                                 train_set.columns == 'DIABETE3']\n",
        "test_inputs, test_targets = test_set.loc[:, test_set.columns != 'DIABETE3'], test_set.loc[:,\n",
        "                                                                             test_set.columns == 'DIABETE3']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvmuKjDKb5pJ"
      },
      "outputs": [],
      "source": [
        "train_inputs.describe()\n",
        "train_inputs.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw1KAe9_Y5ul"
      },
      "source": [
        "### Univariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmFOMxfzxuMu"
      },
      "source": [
        "zkoukáme v rámci této analýzy samostatné parametry, především jejich rozložení. Zjistili jsme, že máme nepoměr kladných a záporných případů, BMI má přibližně normální rozdělení, ostatní zkoumané kategorické parametry povětšinou nejsou vyrovnané a numerické nemají normální rozdělení. Také máme spoustu odpovědí typu \"Nevím/Nechci odpovídat\", které musíme nějak dále řešit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ui_n0uIeeVlU"
      },
      "outputs": [],
      "source": [
        "train_set[train_set._BMI5 < 6500]._BMI5.hist(bins=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpXeAXVdZ2J1"
      },
      "outputs": [],
      "source": [
        "# sns.countplot(data=train_targets[train_targets.DIABETE3 < 7], x='DIABETE3')\n",
        "\n",
        "labels = {1: 'Yes', 2: 'Yes, during pregnancy', 3: 'No', 4: 'Refuse to answer'}\n",
        "to_remove = [7, 9]\n",
        "modified_train_targets = train_targets[~train_targets['DIABETE3'].isin(to_remove)]\n",
        "\n",
        "modified_train_targets['DIABETE3'] = modified_train_targets['DIABETE3'].replace(labels)\n",
        "\n",
        "\n",
        "sns.countplot(data=modified_train_targets, x='DIABETE3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXgJi4MZCD4t"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=train_set, x='SMOKE100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPFVWGl1amM8"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=train_set[train_set.SMOKE100 < 7], x='SMOKE100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUc0RNrpa7gd"
      },
      "outputs": [],
      "source": [
        "train_set[train_set.PHYSHLTH < 31].PHYSHLTH.hist(bins=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC-oqeGEbM30"
      },
      "outputs": [],
      "source": [
        "train_set[train_set.MENTHLTH < 31].MENTHLTH.hist(bins=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc3aTq71bUp8"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=train_set[train_set.INCOME2 < 77], x='INCOME2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtMEroVwa6pF"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=train_set, y='INCOME2', order=train_set[train_set.INCOME2 < 77]['INCOME2'].value_counts().index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuRWpPTrde1D"
      },
      "outputs": [],
      "source": [
        "for column in [\n",
        "    \"MEDCOST\",\n",
        "    \"DIFFWALK\",\n",
        "    \"SMOKE100\",\n",
        "    \"_MICHD\"\n",
        "]:\n",
        "    sns.countplot(\n",
        "        data=train_set, y=column, order=train_set[train_set[column] < 7][column].value_counts().index\n",
        "    )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj5fSHxMZoI9"
      },
      "source": [
        "### Bivariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFZq1GZwzMRp"
      },
      "source": [
        "Zde jsme se rozhodli porovnat počty lidí s diabetem podle pohlaví a nezjistili jsme žádné výrazné rozdíly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oTmXvi3eVlS"
      },
      "outputs": [],
      "source": [
        "train_set.hist(column='DIABETE3', by='SEX')\n",
        "\n",
        "# POCET ZIEN\n",
        "print(\"Pocet zen: \" , train_set[train_set.SEX == 2].shape[0])\n",
        "\n",
        "# POCET MUZOV\n",
        "print(\"Pocet muzu: \" , train_set[train_set.SEX == 1].shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RypuWbqGZsG7"
      },
      "source": [
        "### Multivariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyZVHAqmzc4K"
      },
      "source": [
        "Použitím heatmap jsme se pokusili najít závislosti mezi jednotlivými parametry, ale většina závislostí není statisticky významná. Výjimkou jsou sloupce **_FRTLT1** a **_VEGTLT1** (jak často člověk konzumuje ovoce / zeleninu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8qU3hK2LJOK"
      },
      "outputs": [],
      "source": [
        "df2 = diabetes[['DIABETE3', '_BMI5']]\n",
        "corr = df2.corr()\n",
        "ax = sns.heatmap(\n",
        "    corr,\n",
        "    vmin=-1, vmax=1, center=0,\n",
        "    cmap=sns.diverging_palette(20, 160, n=256),\n",
        "    square=False,\n",
        ")\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=50,\n",
        "    horizontalalignment=\"right\"\n",
        ");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoBNWQU8eVlT"
      },
      "outputs": [],
      "source": [
        "df = train_set.replace({'_TOTINDA': {7:0.5, 9:0.5},\n",
        "                       '_RFHYPE5': {7:0.5, 9:0.5},\n",
        "                       'TOLDHI2': {7:0.5, 9:0.5},\n",
        "                       '_CHOLCHK': {7:0.5, 9:0.5},\n",
        "                       'SMOKE100': {7:0.5, 9:0.5},\n",
        "                       'CVDSTRK3': {7:0.5, 9:0.5},\n",
        "                       '_MICHD': {7:0.5, 9:0.5},\n",
        "                       '_RFDRHV5': {7:0.5, 9:0.5},\n",
        "                       'HLTHPLN1': {7:0.5, 9:0.5},\n",
        "                       'DIFFWALK': {7:0.5, 9:0.5}})\n",
        "\n",
        "corr = df.corr()\n",
        "ax = sns.heatmap(\n",
        "    corr,\n",
        "    vmin=-1, vmax=1, center=0,\n",
        "    cmap=sns.diverging_palette(20, 160, n=256),\n",
        "    square=False,\n",
        ")\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=50,\n",
        "    horizontalalignment=\"right\"\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBCHhzi-kolt"
      },
      "source": [
        "## Předzpracování dat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6BccdUk1FDi"
      },
      "source": [
        "Odpovědi \"nevím/nechci odpovídat\" jsme nahradili za nan hodnoty, pokud sloupec s numerickými hodnotami obsahoval hodnotu, která se má interpretovat jako \"nevím/nechci odpovídat\", tak jsme vytvořili nový sloupec obsahující informaci, zdali člověk odpověděl a datnou hodnotu jsme nahradili za nan.\n",
        "\n",
        "Na sloupce s kategorickými honotami jsme použili OneHotEncoder, na ordinální OrdinalEncoder a na numerické MinMaxScaler. Hodnoty nan jsme v této fázi nemazali. Díky tomuto rozhodnutí můžeme vytvořit dvě sady dat, jednu, kde odstraníme řádky obsahující nan hodnoty a druhou, kde chybějící hodnoty doplníme pomocí imputeru uvnitř v rámci pipeline jednotlivých modelů."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5O9Wkyf2xC4"
      },
      "outputs": [],
      "source": [
        "train_set = train_set.replace({\n",
        "    # 1 = YES, 0 = NO\n",
        "    'DIABETE3': {2: 1, 3: 0, 4: 0, 7: np.nan, 9: np.nan}\n",
        "})\n",
        "\n",
        "test_set = test_set.replace({\n",
        "    # 1 = YES, 0 = NO\n",
        "    'DIABETE3': {2: 1, 3: 0, 4: 0, 7: np.nan, 9: np.nan}\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udki7Mp8MjKp"
      },
      "outputs": [],
      "source": [
        "def preprocessing(df):\n",
        "  # features to treat the same:\n",
        "  # (1 yes, 2 no, 9 don't know/refused/missing) # '_TOTINDA', '_FRTLT1', '_VEGLT1', '_RFDRHV5'\n",
        "  # (1 yes, 2 no, 7 don't know, 9 refused) # 'HLTHPLN1', 'MEDCOST', 'DIFFWALK'\n",
        "  # (1-5 best to worst, 7 don't know, 9 refused) # 'GENHLTH'\n",
        "  \n",
        "  df = df.replace({'HLTHPLN1': {7: None, 9: None},    # prepaid health care coverage\n",
        "                  'MEDCOST': {7: None, 9: None},     # did not have money for doctor\n",
        "                    '_RFHYPE5': {7: None, 9: None},\n",
        "                  'TOLDHI2': {7: None, 9: None},\n",
        "                  'SMOKE100': {7: None, 9: None},\n",
        "                   'DIFFWALK': {7: None, 9: None},\n",
        "                  'CVDSTRK3': {7: None, 9: None},\n",
        "                  '_MICHD': {7: None, 9: None},\n",
        "                  'GENHLTH': {7: None, 9: None},  # added general health\n",
        "                   '_AGEG5YR': {14: None},\n",
        "                   'EDUCA': {9: None},\n",
        "                   '_RFHYPE5': {9: None},\n",
        "                   '_FRTLT1': {9: None},\n",
        "                   '_VEGLT1': {9: None},\n",
        "                   '_RFDRHV5': {9: None},\n",
        "                   '_TOTINDA': {9: None}\n",
        "                  })\n",
        "  \n",
        "  two_val_cols = ['_TOTINDA', '_FRTLT1', '_VEGLT1', '_RFDRHV5', 'HLTHPLN1', \n",
        "                  'MEDCOST', 'DIFFWALK', 'SMOKE100', 'CVDSTRK3', \n",
        "                  '_MICHD', '_RFHYPE5', 'TOLDHI2', 'SEX']  #### columns that after previous replace contain only 2 possible values (+ sex)\n",
        "\n",
        "  # decrease by one (not sure if it will have any effect, but it certainly should not hurt)\n",
        "  for col in two_val_cols:\n",
        "    df = df.replace({f'{col}': {1: 0, 2: 1}})\n",
        "\n",
        "  \"\"\"columns = ['HLTHPLN1', 'MEDCOST', '_RFHYPE5', 'TOLDHI2', 'SMOKE100', 'CVDSTRK3', '_MICHD']\"\"\"  #### not used\n",
        "\n",
        "  \"\"\"df = df.replace({'GENHLTH': {7: 3, 9: 4}})  # general health\"\"\"  #### baseless assumption\n",
        "\n",
        "  df = df.replace({'PHYSHLTH': {88 : 0}, 'MENTHLTH': {88 : 0}})\n",
        "\n",
        "  \"\"\"df = df.replace({'CHOLCHK': {7: 5, 9: 5}}) # cholesterol check\"\"\"  #### does not make sense ..values in data are 1,2,3,9\n",
        "\n",
        "  # Splitting 'group of values' and 'answered/not anwered' options into\n",
        "  # seperate columns\n",
        "  # 88 - None\n",
        "  # 77 - Don't know\n",
        "  # 99 -refused\n",
        "  to_split = ['PHYSHLTH', 'MENTHLTH', 'INCOME2']\n",
        "  for col in to_split:\n",
        "    # for 'PHYSHLTH', 'MENTHLTH' the value is 'days'\n",
        "    # for 'INCOME2' values 1 - 7 represent category of income \n",
        "    # 'Not answered' 0\n",
        "    # 'Answered' 1\n",
        "    df[[f'{col}_VALUE', f'{col}_ANSWERED']] = df.apply(lambda row: (None, 0) if row[col] in [77, 99] else (row[col], 1), axis=1, result_type='expand')\n",
        "\n",
        "  df['INCOME2_VALUE'] = df['INCOME2_VALUE'].apply(lambda x: 9 - x if x != 0 else 0)\n",
        "\n",
        "  df = df.drop(columns=to_split)\n",
        "  # Option for handling missing values; drop all rows with np.nan\n",
        "  df = df.dropna(subset=['DIABETE3'])\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gb0J1hDNUZEq"
      },
      "outputs": [],
      "source": [
        "train_inputs.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lf7oh3PkFo6e"
      },
      "outputs": [],
      "source": [
        "# train_inputs_preprocessed = preprocessing(train_inputs)\n",
        "train_set_preprocessed = preprocessing(train_set)\n",
        "test_set_preprocessed = preprocessing(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdRM4ndbUVoK"
      },
      "outputs": [],
      "source": [
        "# train_inputs_preprocessed.head()\n",
        "train_set_preprocessed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shubqiB6PPTI"
      },
      "outputs": [],
      "source": [
        "# Aby sa mohla pipelina pouzit na rozne modely, trenovacie/testovacie data\n",
        "def get_transform_pipeline():\n",
        "  numerical_features = ['_BMI5', 'PHYSHLTH_VALUE', 'MENTHLTH_VALUE', '_AGEG5YR']\n",
        "  ordinal_features = ['INCOME2_VALUE', 'EDUCA', 'GENHLTH']\n",
        "  # maybe use all of features?:\n",
        "  \"\"\"categorical_features = ['_TOTINDA', '_CHOLCHK', '_FRTLT1', '_VEGLT1', '_RFDRHV5', 'HLTHPLN1', 'MEDCOST', 'GENHLTH', 'INCOME2_ANSWERED', 'PHYSHLTH_ANSWERED', 'MENTHLTH_ANSWERED', '_RFHYPE5', 'TOLDHI2', 'SMOKE100', 'CVDSTRK3', '_RFDRHV5', 'DIFFWALK', 'SEX', '_MICHD']\"\"\"\n",
        "  categorical_features = ['_CHOLCHK']  #### only those with more than 2 answers\n",
        "  return Pipeline([\n",
        "      ('selector', ColumnTransformer([\n",
        "          (\"one-hot\", OneHotEncoder(), categorical_features),\n",
        "          ('ordinal', OrdinalEncoder(), ordinal_features),\n",
        "          ('scaler', MinMaxScaler(feature_range=(0,1)), numerical_features + ordinal_features)\n",
        "      ], remainder='passthrough'))\n",
        "  ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pFVE2Tz1UqO"
      },
      "outputs": [],
      "source": [
        "transform_pipeline = get_transform_pipeline()\n",
        "train_set_transformed = pd.DataFrame(transform_pipeline.fit_transform(train_set_preprocessed))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oQ4zlbLkujt"
      },
      "outputs": [],
      "source": [
        "# train_transformed[train_transformed.columns[30:]].tail()\n",
        "# train_transformed.info()\n",
        "train_set_transformed[train_set_transformed.columns[9:]].tail()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHDyOsHHVz0R"
      },
      "outputs": [],
      "source": [
        "train_set_transformed.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_transformed.drop()"
      ],
      "metadata": {
        "id": "ULEOD8A5HrFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rozhodli jsme se nedělat extrakce rysů v předzpracování dát, protože všechny sloupci podle našeho názoru mozou se hodit. Nechali jsme to jednotlivým pipelines na zpracování pomoci SelectKBest."
      ],
      "metadata": {
        "id": "1AktwMblerWy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtA6_WKJ3qYw"
      },
      "source": [
        "## Datasety"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsWHKYyC3jls"
      },
      "source": [
        "Příprava 2 datasetů zmíněných výše."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EjaJwVl3qE4"
      },
      "outputs": [],
      "source": [
        "# dropped nans\n",
        "train_sp_no_na = train_set_preprocessed.dropna()\n",
        "test_sp_no_na = test_set_preprocessed.dropna()\n",
        "train_X_no_nans, train_y_no_nans = train_sp_no_na.drop(columns=['DIABETE3', 'INCOME2_ANSWERED', 'PHYSHLTH_ANSWERED', 'MENTHLTH_ANSWERED']), train_sp_no_na['DIABETE3']\n",
        "test_X_no_nans, test_y_no_nans = test_sp_no_na.drop(columns=['DIABETE3', 'INCOME2_ANSWERED', 'PHYSHLTH_ANSWERED', 'MENTHLTH_ANSWERED']), test_sp_no_na['DIABETE3']\n",
        "\n",
        "# kept nans\n",
        "train_X, train_y = train_set_preprocessed.drop(columns=['DIABETE3']), train_set_preprocessed['DIABETE3']\n",
        "test_X, test_y = test_set_preprocessed.drop(columns=['DIABETE3']), test_set_preprocessed['DIABETE3']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aju1UBiR6jlH"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhOxBZ5A4XBk"
      },
      "source": [
        "Jako hlavní metriku jsme se rozhodli použít recall, z důvodu charakteru dat, kde je důležité minimalizovat počet *False Negative*. Další metriky, které používáme jsou *f1_score, precision*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EldR15zdNyZg"
      },
      "outputs": [],
      "source": [
        "rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False, squared=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQP1t9645Kz2"
      },
      "outputs": [],
      "source": [
        "def print_score(prediction, inputs_y):\n",
        "  print(f\"f1_score: {f1_score(inputs_y, prediction):.4f}  (higher == better)\")\n",
        "  print(f\"Recall: {recall_score(inputs_y, prediction):.4f}  (higher == better)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDBFXLWgRpYN"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "# Minimalize FN\n",
        "def display_confusion_matrix(pipeline, test_X, test_y):\n",
        "  sns.reset_orig()\n",
        "  ConfusionMatrixDisplay.from_estimator(\n",
        "      pipeline, test_X, test_y, xticks_rotation=\"vertical\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voj3QVbBCdGD"
      },
      "outputs": [],
      "source": [
        "def visualize(pipeline, train_X, train_y):\n",
        "    scoring_metrics = ['f1', 'neg_mean_squared_error', 'precision', 'recall']\n",
        "    labels = ['F1', 'RMSE', 'Precision', 'Recall']\n",
        "    for i, scoring_metric in enumerate(scoring_metrics):\n",
        "      viz = ValidationCurve(\n",
        "          pipeline,\n",
        "          param_name=\"selectkbest__k\",\n",
        "          param_range=np.arange(2, 22),\n",
        "          cv=10,\n",
        "          scoring=scoring_metric,\n",
        "          title=f'Validaiton curve for {labels[i]} metric'\n",
        "      )\n",
        "      viz.fit(train_X, train_y)\n",
        "      viz.show()\n",
        "      sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqF4-TZO60ai"
      },
      "source": [
        "# Modely\n",
        "\n",
        "Jako baseline jsme použili threshold podle BMI. Jako modely jsme zvolili Decision Tree, Random Forest a KNN. Decision tree je dobrá volba pro nevyvážená data, protože se zaměřují na funkce, které jsou nejvhodnější pro rozdělení tříd a jsou relativně jednoduché a snadno interpretovatelné. Random Forest používáme, abychom mohli porovnat s Decision Tree, jelikož oba fungují na stejném základu. Pro KNN jsme se rozhodli, jelikož dobře funguje s nízkodimenzionálními daty, ale na druhou stranu nefunguje moc dobře s nevyrovnané data, takže ta volba byla spíš pro zvědavost.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRNy-7egQeOL"
      },
      "source": [
        "## Baseline\n",
        "\n",
        "Pokud má člověk hodnotu BMI vyšší než 4000, tak vrací, že člověk má Diabetes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOfFDzHXi1Jr"
      },
      "outputs": [],
      "source": [
        "pred_y = test_y.copy()\n",
        "for (index, row) in test_X.iterrows():\n",
        "  if row._BMI5 > 4000:\n",
        "    pred_y[index] = 1\n",
        "  else:\n",
        "    pred_y[index] = 0\n",
        "\n",
        "print_score(pred_y, test_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6W-y24iQZzH"
      },
      "source": [
        "## Decision tree\n",
        "\n",
        "Decision tree je algoritmus strojového učení používaný pro klasifikaci a predikci. Jedná se o stromovou strukturu, ve které každý uzel reprezentuje rozhodování na základě určitého atributu a každá hrana spojuje uzel s jeho potomky. Na základě hodnot atributů vstupních dat se postupně prochází strom a rozhoduje se o klasifikaci nebo predikci cílové proměnné. Při trénování decision tree algoritmus hledá nejlepší atributy pro rozdělení dat a snižuje tak míru nejistoty (entropy) v každém uzlu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu0eXDJuzwys"
      },
      "outputs": [],
      "source": [
        "tree_pipeline1 = Pipeline(\n",
        "    [\n",
        "        (\"transform\", transform_pipeline),\n",
        "        (\"imputer\", SimpleImputer()),\n",
        "        (\"selectkbest\", SelectKBest(score_func=chi2)),\n",
        "        (\"model\", DecisionTreeClassifier(\n",
        "            criterion='entropy',\n",
        "            class_weight='balanced'\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "parameters = {\n",
        "    'model__max_depth': [24, 32],\n",
        "    'model__min_samples_leaf': [3, 30],\n",
        "    'selectkbest__k' : [8, 22],\n",
        "    'model__max_leaf_nodes': [None, 50],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47U1X0zRj1JL"
      },
      "outputs": [],
      "source": [
        "# Kept nans\n",
        "print('KEPT NANs')\n",
        "\n",
        "gscv_kept = GridSearchCV(tree_pipeline1, parameters)\n",
        "gscv_kept.fit(train_X, train_y)\n",
        "\n",
        "best_model_kept = gscv_kept.best_estimator_\n",
        "prediction_kept = best_model_kept.predict(test_X)\n",
        "\n",
        "print('Best hyperparameters:', gscv_kept.best_params_)\n",
        "print_score(prediction_kept, test_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1iYCIcvHQOL"
      },
      "outputs": [],
      "source": [
        "visualize(\n",
        "    best_model_kept,\n",
        "    train_X,\n",
        "    train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIrc8_8rj2HP"
      },
      "outputs": [],
      "source": [
        "print('Confusion matrix')\n",
        "display_confusion_matrix(best_model_kept, test_X, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TgJ257Nntxn"
      },
      "outputs": [],
      "source": [
        "# Dropped nans\n",
        "tree_pipeline2 = Pipeline(\n",
        "    [\n",
        "        (\"transform\", transform_pipeline),\n",
        "        (\"selectkbest\", SelectKBest(score_func=chi2)),\n",
        "        (\"model\", DecisionTreeClassifier(\n",
        "            criterion='entropy',\n",
        "            class_weight='balanced'\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "print('DROPPED NANs')\n",
        "gscv_dropped = GridSearchCV(tree_pipeline2, parameters)\n",
        "gscv_dropped.fit(train_X_no_nans, train_y_no_nans)\n",
        "\n",
        "best_model_dropped = gscv_dropped.best_estimator_\n",
        "prediction_dropped = best_model_dropped.predict(test_X_no_nans)\n",
        "\n",
        "print('Best hyperparameters:', gscv_dropped.best_params_)\n",
        "print_score(prediction_dropped, test_y_no_nans)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43clLVV7HVR8"
      },
      "outputs": [],
      "source": [
        "visualize(\n",
        "    best_model_kept,\n",
        "    train_X_no_nans,\n",
        "    train_y_no_nans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7yfWHOunyZx"
      },
      "outputs": [],
      "source": [
        "print('Confusion matrix')\n",
        "display_confusion_matrix(best_model_dropped, test_X_no_nans, test_y_no_nans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD-oBYgx08at"
      },
      "source": [
        "## Random Forest\n",
        "\n",
        "Random forest je algoritmus strojového učení, který využívá rozhodovací stromy pro klasifikaci a predikci. Jedná se o soubor stromů, kde každý strom je trénován na náhodně vybrané podmnožině dat a s náhodně vybranými atributy. V průběhu predikce je pak výsledek určen hlasováním mezi výsledky jednotlivých stromů. Tento přístup umožňuje snížit riziko přetrénování, zlepšit přesnost predikce a zvyšovat odolnost algoritmu vůči šumu v datech."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvgZw0sZQIKU"
      },
      "outputs": [],
      "source": [
        "forest_pipeline = Pipeline(\n",
        "    [\n",
        "        (\"transform\", transform_pipeline),\n",
        "        # (\"imputer\", KNNImputer()),\n",
        "        (\"forest\", RandomForestClassifier())\n",
        "    ])\n",
        "\n",
        "forest_pipeline.fit(train_X_no_nans, train_y_no_nans)\n",
        "prediction = forest_pipeline.predict(test_X_no_nans)\n",
        "print_score(prediction, test_y_no_nans)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIzC4XiUFoSn"
      },
      "outputs": [],
      "source": [
        "# finding best hyperparameters\n",
        "parameters = {'forest__random_state': [42],\n",
        "              \"forest__n_estimators\": [100, 200],\n",
        "              'forest__criterion': [\"entropy\", \"log_loss\"],\n",
        "              'forest__max_depth': [15, 20],\n",
        "              'forest__min_samples_leaf': [1, 2],\n",
        "              'forest__max_samples': [0.8, 1.0],\n",
        "              \"forest__min_samples_split\": [2, 5],\n",
        "              'forest__max_features': [\"log2\"],\n",
        "              'forest__class_weight': [\"balanced\"],\n",
        "              }\n",
        "\n",
        "scorer = make_scorer(recall_score)\n",
        "\n",
        "forest_pipeline_optimized = GridSearchCV(forest_pipeline, parameters, cv=5, scoring=scorer, verbose=1)\n",
        "forest_pipeline_optimized.fit(train_X_no_nans, train_y_no_nans)\n",
        "\n",
        "print(\"optimized:\")\n",
        "print(f1_score(forest_pipeline_optimized.predict(test_X_no_nans), test_y_no_nans, average=None))\n",
        "\n",
        "print()\n",
        "print(\"best found params:\")\n",
        "\n",
        "forest_pipeline_optimized.best_params_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7HPv4EZKjjc"
      },
      "outputs": [],
      "source": [
        "display_confusion_matrix(forest_pipeline_optimized, test_X_no_nans, test_y_no_nans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYmEOqn4FtJ-"
      },
      "outputs": [],
      "source": [
        "forest_classifier = RandomForestClassifier(class_weight='balanced',\n",
        "                                           bootstrap=True, \n",
        "                                           criterion='entropy', \n",
        "                                           max_depth=15, \n",
        "                                           max_features='log2', \n",
        "                                           max_samples=1.0, \n",
        "                                           min_samples_leaf=2, \n",
        "                                           min_samples_split=5,\n",
        "                                           n_estimators=100,\n",
        "                                           random_state=42)\n",
        "\n",
        "forest_pipeline1 = Pipeline(\n",
        "    [\n",
        "        (\"transform\", transform_pipeline),\n",
        "        (\"forest\", forest_classifier)\n",
        "    ])\n",
        "\n",
        "print(\"dropped nans\")\n",
        "forest_pipeline1.fit(train_X_no_nans, train_y_no_nans)\n",
        "prediction1 = forest_pipeline1.predict(test_X_no_nans)\n",
        "print_score(prediction1,test_y_no_nans)\n",
        "\n",
        "\n",
        "forest_pipeline2 = Pipeline(\n",
        "    [\n",
        "        (\"transform\", transform_pipeline),\n",
        "        (\"imputer\", KNNImputer()),\n",
        "        (\"forest\", forest_classifier)\n",
        "    ])\n",
        "\n",
        "print()\n",
        "print(\"imputed values\")\n",
        "forest_pipeline2.fit(train_X, train_y)\n",
        "prediction2 = forest_pipeline2.predict(test_X)\n",
        "print_score(prediction2, test_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tEi3wo7O26d"
      },
      "source": [
        "## KNN\n",
        "\n",
        "K-Nearest Neighbors (KNN) je algoritmus strojového učení používaný pro klasifikaci a regresi. Algoritmus při klasifikaci přiřazuje novému datovému bodu třídu na základě nejbližších sousedů v trénovacích datech. KNN vyhledává K nejbližších sousedů pomocí eukleidovské vzdálenosti nebo jiné metriky a třídu nového bodu určí podle většiny tříd jeho nejbližších sousedů. Při regresi algoritmus predikuje hodnotu cílové proměnné na základě průměru hodnot nejbližších sousedů. Volbou parametru K lze ovlivnit vliv šumu v datech na predikci."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqW-N_Y8-1-z"
      },
      "source": [
        "Jako první krok byly udělané 2 pipeliny pro dataset s nan hodnotami, které pak budou nahrazené pomocí KNNImputer, a také dataset bez nan hodnot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owF5wRQ4Me1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "499299cc-773b-40a3-eb36-3b6ef1e268e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score: 0.2798  (higher == better)\n",
            "Recall: 0.2157  (higher == better)\n"
          ]
        }
      ],
      "source": [
        "knn_pipeline_1 = make_pipeline(\n",
        "        transform_pipeline,\n",
        "        KNNImputer(),\n",
        "        KNeighborsClassifier(),\n",
        "    )\n",
        "\n",
        "# dataset with umputed NaN values\n",
        "knn_pipeline_1.fit(train_X, train_y)\n",
        "prediction_knn = knn_pipeline_1.predict(test_X)\n",
        "print_score(prediction_knn, test_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3hHTJ2qPW8y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cee6bfa-5fe2-4b5e-8437-cac09a5d9864"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score: 0.2743  (higher == better)\n",
            "Recall: 0.2037  (higher == better)\n"
          ]
        }
      ],
      "source": [
        "knn_pipeline_2 = make_pipeline(\n",
        "        transform_pipeline,\n",
        "        SelectKBest(k=5),\n",
        "        KNeighborsClassifier(),\n",
        "    )\n",
        "\n",
        "# dataset with dropped NaN values\n",
        "knn_pipeline_2.fit(train_X_no_nans, train_y_no_nans)\n",
        "prediction_knn_no_nans = knn_pipeline_2.predict(test_X_no_nans)\n",
        "print_score(prediction_knn_no_nans, test_y_no_nans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oezarAp_9-qf"
      },
      "source": [
        "Pro optimalizaci byli použité relevantní paramentry z KNeigboursClassififer a KBest. Optimalizace byla udělaná s pomoci datové sady bez hodnot nan pro snížení času trvání:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n6Op8UDRRaq"
      },
      "outputs": [],
      "source": [
        "parameters = {'kneighborsclassifier__n_neighbors': [3, 5, 7],\n",
        "              'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
        "              'kneighborsclassifier__algorithm': ['ball_tree', 'kd_tree', 'auto'],\n",
        "              'selectkbest__k' : [2, 3, 4, 5, 6],\n",
        "              }\n",
        "\n",
        "pipeline_optimized = GridSearchCV(knn_pipeline_2, parameters, cv=5, scoring = 'recall')\n",
        "pipeline_optimized.fit(train_X_no_nans, train_y_no_nans)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"optimized:\")\n",
        "print(f1_score(pipeline_optimized.predict(train_X_no_nans), train_y_no_nans, average=None))\n",
        "\n",
        "print()\n",
        "print(\"best found params:\")\n",
        "\n",
        "pipeline_optimized.best_params_"
      ],
      "metadata": {
        "id": "qf2mmJgQGXd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vemNec38_BYG"
      },
      "source": [
        "Upravené pipeliny s pomoci předchozích výsledků:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toSovagmLi3Q"
      },
      "outputs": [],
      "source": [
        "knn_pipeline_1_optimized = make_pipeline(\n",
        "        transform_pipeline,\n",
        "        KNNImputer(),\n",
        "        SelectKBest(k=6),\n",
        "        KNeighborsClassifier(n_neighbors=3, algorithm='ball_tree', weights='distance'),\n",
        "    )\n",
        "\n",
        "# dataset with umputed NaN values\n",
        "knn_pipeline_1_optimized.fit(train_X, train_y)\n",
        "prediction_knn_optimized = knn_pipeline_1_optimized.predict(test_X)\n",
        "print_score(prediction_knn_optimized, test_y)\n",
        "\n",
        "\n",
        "knn_pipeline_2_optimized = make_pipeline(\n",
        "        transform_pipeline,\n",
        "        SelectKBest(k=6),\n",
        "        KNeighborsClassifier(n_neighbors=3, algorithm='ball_tree', weights='distance'),\n",
        "    )\n",
        "\n",
        "# dataset with dropped NaN values\n",
        "knn_pipeline_2_optimized.fit(train_X_no_nans, train_y_no_nans)\n",
        "prediction_knn_no_nans_optimized = knn_pipeline_2_optimized.predict(test_X_no_nans)\n",
        "print_score(prediction_knn_no_nans_optimized, test_y_no_nans)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_confusion_matrix(knn_pipeline_2_optimized, test_X_no_nans, test_y_no_nans)"
      ],
      "metadata": {
        "id": "io_rmMLBgVZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w45UUq31omf"
      },
      "source": [
        "\n",
        "Jak bylo zmíněno na začátku, KNN nefunguje moc dobře s nevyrovnané data a nakonec to převážilo jeho schopnost pracovat s nizkodimenzionalni data. Výsledky jsou horší než naivní baseline. GridSearch o trochu zlepšil výsledky. Recall KNN modelu je skoro 4krať větší než v případě baseline, accuracy a precision jsou větší. Ale rmse zůstává skoro stejný jako v baseline. Další nevýhoda KNN je taky to, že má to velkou výpočetní cenu. Výsledky víceméně splnily očekávání - většina metrik se zlepšily.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HkIu5cN-nU1"
      },
      "source": [
        "## Finální vyhodnocení\n",
        "\n",
        "\n",
        "Na konci jsme zjistili, že všechny testované modely dosáhly lepších výsledků než baseline model, který jsme zvolili. Jako metriky pro porovnání modelu jsme se rozhodli pro recall, jelikož redukovat počet False Negative ve zdravotnických datech je důležitý. Také to srovnáváme podle F1_score,protože  je to běžná metrika při vyhodnocení modelu, kterou jsme se rohdoli přidat jako doprovodní pro lepší srovnávání.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Výsledky pro dataset s nan hodnoty:"
      ],
      "metadata": {
        "id": "yjJ2qQ0nd3Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Decision Tree model:\")\n",
        "print_score(prediction_kept, test_y)\n",
        "print(\"Random Forest model:\")\n",
        "print_score(prediction2,test_y)\n",
        "print(\"KNN model:\")\n",
        "print_score(prediction_knn_optimized, test_y)"
      ],
      "metadata": {
        "id": "ysM-VBJ1cniI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Výsledky pro dataset bez nan hodnot:"
      ],
      "metadata": {
        "id": "S_rEjxtwd-jX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Decision Tree model:\")\n",
        "print_score(prediction_dropped, test_y_no_nans)\n",
        "print(\"Random Forest model:\")\n",
        "print_score(prediction1,test_y_no_nans)\n",
        "print(\"KNN model:\")\n",
        "print_score(prediction_knn_no_nans, test_y_no_nans)"
      ],
      "metadata": {
        "id": "aj1nqccebJ6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nejlepších výsledků dosáhl model Radom Forest, jak jsme předpokládali na začátku. Je to nejvhodnější model pro podobný typ úkolů."
      ],
      "metadata": {
        "id": "cgh6hKOUaKbd"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}