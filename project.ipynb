{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valkucz/ib031/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O50hoEqQJMn4"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from yellowbrick.model_selection import ValidationCurve\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, make_scorer, mean_squared_error, ConfusionMatrixDisplay\n",
        "from sklearn.pipeline import make_pipeline, Pipeline, FeatureUnion\n",
        "from sklearn.compose import make_column_transformer, make_column_selector, ColumnTransformer\n",
        "from sklearn.impute import KNNImputer, SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, MinMaxScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "sns.set() \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijskxtdjka9F"
      },
      "source": [
        "## Explorační analýza\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset obsahuje medicinská data různých lidí. Dataset má 23 sloupců. Cílem je identifikovat riziko cukrovky. To představuje sloupec DIABETE3. Kromě toho dataset obsahuje sloupce popisující mentalní zdraví, fyzické zdraví, kuřácké návyky, či přístup k zdravotní péči. Data jsou zakódováná číselně a většinou se jedná o kategorická data. V rámci explorační analýzy bylo potřeba data částečně předspracovat, abychom získali použitelné výsledky z grafů."
      ],
      "metadata": {
        "id": "Y0g9cVrcvx88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zo7yDsfbeVlS"
      },
      "outputs": [],
      "source": [
        "diabetes = pd.read_csv('./diabetes.csv', index_col=0)\n",
        "diabetes.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nd9QZNEdZgDP"
      },
      "outputs": [],
      "source": [
        "diabetes.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzaPI1If5_Hs"
      },
      "outputs": [],
      "source": [
        "diabetes.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o95x2WqVeVlU"
      },
      "outputs": [],
      "source": [
        "diabetes = diabetes.drop(columns=['ID'])\n",
        "\n",
        "train_set, test_set = train_test_split(diabetes, test_size=0.2, random_state=42)\n",
        "\n",
        "train_inputs, train_targets = train_set.loc[:, train_set.columns != 'DIABETE3'], train_set.loc[:,\n",
        "                                                                                 train_set.columns == 'DIABETE3']\n",
        "test_inputs, test_targets = test_set.loc[:, test_set.columns != 'DIABETE3'], test_set.loc[:,\n",
        "                                                                             test_set.columns == 'DIABETE3']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvmuKjDKb5pJ"
      },
      "outputs": [],
      "source": [
        "train_inputs.describe()\n",
        "train_inputs.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw1KAe9_Y5ul"
      },
      "source": [
        "### Univariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "zkoukáme v rámci této analýzy samostatné parametry, především jejich rozložení. Zjistili jsme, že máme nepoměr kladných a záporných případů, BMI má přibližně normální rozdělení, ostatní zkoumané kategorické parametry povětšinou nejsou vyrovnané a numerické nemají normální rozdělení. Také máme spoustu odpovědí typu \"Nevím/Nechci odpovídat\", které musíme nějak dále řešit."
      ],
      "metadata": {
        "id": "FmFOMxfzxuMu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ui_n0uIeeVlU"
      },
      "outputs": [],
      "source": [
        "train_set[train_set._BMI5 < 6500]._BMI5.hist(bins=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpXeAXVdZ2J1"
      },
      "outputs": [],
      "source": [
        "# sns.countplot(data=train_targets[train_targets.DIABETE3 < 7], x='DIABETE3')\n",
        "\n",
        "labels = {1: 'Yes', 2: 'Yes, during pregnancy', 3: 'No', 4: 'Refuse to answer'}\n",
        "to_remove = [7, 9]\n",
        "modified_train_targets = train_targets[~train_targets['DIABETE3'].isin(to_remove)]\n",
        "\n",
        "modified_train_targets['DIABETE3'] = modified_train_targets['DIABETE3'].replace(labels)\n",
        "\n",
        "\n",
        "sns.countplot(data=modified_train_targets, x='DIABETE3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXgJi4MZCD4t"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=train_set, x='SMOKE100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPFVWGl1amM8"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=train_set[train_set.SMOKE100 < 7], x='SMOKE100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUc0RNrpa7gd"
      },
      "outputs": [],
      "source": [
        "train_set[train_set.PHYSHLTH < 31].PHYSHLTH.hist(bins=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC-oqeGEbM30"
      },
      "outputs": [],
      "source": [
        "train_set[train_set.MENTHLTH < 31].MENTHLTH.hist(bins=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc3aTq71bUp8"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=train_set[train_set.INCOME2 < 77], x='INCOME2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtMEroVwa6pF"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=train_set, y='INCOME2', order=train_set[train_set.INCOME2 < 77]['INCOME2'].value_counts().index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuRWpPTrde1D"
      },
      "outputs": [],
      "source": [
        "for column in [\n",
        "    \"MEDCOST\",\n",
        "    \"DIFFWALK\",\n",
        "    \"SMOKE100\",\n",
        "    \"_MICHD\"\n",
        "]:\n",
        "    sns.countplot(\n",
        "        data=train_set, y=column, order=train_set[train_set[column] < 7][column].value_counts().index\n",
        "    )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj5fSHxMZoI9"
      },
      "source": [
        "### Bivariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zde jsme se rozhodli porovnat počty lidí s diabetem podle pohlaví a nezjistili jsme žádné výrazné rozdíly."
      ],
      "metadata": {
        "id": "aFZq1GZwzMRp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oTmXvi3eVlS"
      },
      "outputs": [],
      "source": [
        "train_set.hist(column='DIABETE3', by='SEX')\n",
        "\n",
        "# POCET ZIEN\n",
        "print(\"Pocet zen: \" , train_set[train_set.SEX == 2].shape[0])\n",
        "\n",
        "# POCET MUZOV\n",
        "print(\"Pocet muzu: \" , train_set[train_set.SEX == 1].shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RypuWbqGZsG7"
      },
      "source": [
        "### Multivariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Použitím heatmap jsme se pokusili najít závislosti mezi jednotlivými parametry, ale většina závislostí není statisticky významná. Výjimkou jsou sloupce **_FRTLT1** a **_VEGTLT1** (jak často člověk konzumuje ovoce / zeleninu)"
      ],
      "metadata": {
        "id": "ZyZVHAqmzc4K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8qU3hK2LJOK"
      },
      "outputs": [],
      "source": [
        "df2 = diabetes[['DIABETE3', '_BMI5']]\n",
        "corr = df2.corr()\n",
        "ax = sns.heatmap(\n",
        "    corr,\n",
        "    vmin=-1, vmax=1, center=0,\n",
        "    cmap=sns.diverging_palette(20, 160, n=256),\n",
        "    square=False,\n",
        ")\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=50,\n",
        "    horizontalalignment=\"right\"\n",
        ");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoBNWQU8eVlT"
      },
      "outputs": [],
      "source": [
        "df = train_set.replace({'_TOTINDA': {7:0.5, 9:0.5},\n",
        "                       '_RFHYPE5': {7:0.5, 9:0.5},\n",
        "                       'TOLDHI2': {7:0.5, 9:0.5},\n",
        "                       '_CHOLCHK': {7:0.5, 9:0.5},\n",
        "                       'SMOKE100': {7:0.5, 9:0.5},\n",
        "                       'CVDSTRK3': {7:0.5, 9:0.5},\n",
        "                       '_MICHD': {7:0.5, 9:0.5},\n",
        "                       '_RFDRHV5': {7:0.5, 9:0.5},\n",
        "                       'HLTHPLN1': {7:0.5, 9:0.5},\n",
        "                       'DIFFWALK': {7:0.5, 9:0.5}})\n",
        "\n",
        "corr = df.corr()\n",
        "ax = sns.heatmap(\n",
        "    corr,\n",
        "    vmin=-1, vmax=1, center=0,\n",
        "    cmap=sns.diverging_palette(20, 160, n=256),\n",
        "    square=False,\n",
        ")\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=50,\n",
        "    horizontalalignment=\"right\"\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBCHhzi-kolt"
      },
      "source": [
        "## Předzpracování dat"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Odpovědi \"nevím/nechci odpovídat\" jsme nahradili za nan hodnoty, pokud sloupec s numerickými hodnotami obsahoval hodnotu, která se má interpretovat jako \"nevím/nechci odpovídat\", tak jsme vytvořili nový sloupec obsahující informaci, zdali člověk odpověděl a datnou hodnotu jsme nahradili za nan.\n",
        "\n",
        "Na sloupce s kategorickými honotami jsme použili OneHotEncoder, na ordinální OrdinalEncoder a na numerické MinMaxScaler. Hodnoty nan jsme v této fázi nemazali. Díky tomuto rozhodnutí můžeme vytvořit dvě sady dat, jednu, kde odstraníme řádky obsahující nan hodnoty a druhou, kde chybějící hodnoty doplníme pomocí imputeru uvnitř v rámci pipeline jednotlivých modelů."
      ],
      "metadata": {
        "id": "H6BccdUk1FDi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5O9Wkyf2xC4"
      },
      "outputs": [],
      "source": [
        "train_set = train_set.replace({\n",
        "    # 1 = YES, 0 = NO\n",
        "    'DIABETE3': {2: 1, 3: 0, 4: 0, 7: np.nan, 9: np.nan}\n",
        "})\n",
        "\n",
        "test_set = test_set.replace({\n",
        "    # 1 = YES, 0 = NO\n",
        "    'DIABETE3': {2: 1, 3: 0, 4: 0, 7: np.nan, 9: np.nan}\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udki7Mp8MjKp"
      },
      "outputs": [],
      "source": [
        "def preprocessing(df):\n",
        "  # features to treat the same:\n",
        "  # (1 yes, 2 no, 9 don't know/refused/missing) # '_TOTINDA', '_FRTLT1', '_VEGLT1', '_RFDRHV5'\n",
        "  # (1 yes, 2 no, 7 don't know, 9 refused) # 'HLTHPLN1', 'MEDCOST', 'DIFFWALK'\n",
        "  # (1-5 best to worst, 7 don't know, 9 refused) # 'GENHLTH'\n",
        "  \n",
        "  df = df.replace({'HLTHPLN1': {7: None, 9: None},    # prepaid health care coverage\n",
        "                  'MEDCOST': {7: None, 9: None},     # did not have money for doctor\n",
        "                    '_RFHYPE5': {7: None, 9: None},\n",
        "                  'TOLDHI2': {7: None, 9: None},\n",
        "                  'SMOKE100': {7: None, 9: None},\n",
        "                   'DIFFWALK': {7: None, 9: None},\n",
        "                  'CVDSTRK3': {7: None, 9: None},\n",
        "                  '_MICHD': {7: None, 9: None},\n",
        "                  'GENHLTH': {7: None, 9: None},  # added general health\n",
        "                   '_AGEG5YR': {14: None},\n",
        "                   'EDUCA': {9: None},\n",
        "                   '_RFHYPE5': {9: None},\n",
        "                   '_FRTLT1': {9: None},\n",
        "                   '_VEGLT1': {9: None},\n",
        "                   '_RFDRHV5': {9: None},\n",
        "                   '_TOTINDA': {9: None}\n",
        "                  })\n",
        "  \n",
        "  two_val_cols = ['_TOTINDA', '_FRTLT1', '_VEGLT1', '_RFDRHV5', 'HLTHPLN1', \n",
        "                  'MEDCOST', 'DIFFWALK', 'SMOKE100', 'CVDSTRK3', \n",
        "                  '_MICHD', '_RFHYPE5', 'TOLDHI2', 'SEX']  #### columns that after previous replace contain only 2 possible values (+ sex)\n",
        "\n",
        "  # decrease by one (not sure if it will have any effect, but it certainly should not hurt)\n",
        "  for col in two_val_cols:\n",
        "    df = df.replace({f'{col}': {1: 0, 2: 1}})\n",
        "\n",
        "  \"\"\"columns = ['HLTHPLN1', 'MEDCOST', '_RFHYPE5', 'TOLDHI2', 'SMOKE100', 'CVDSTRK3', '_MICHD']\"\"\"  #### not used\n",
        "\n",
        "  \"\"\"df = df.replace({'GENHLTH': {7: 3, 9: 4}})  # general health\"\"\"  #### baseless assumption\n",
        "\n",
        "  df = df.replace({'PHYSHLTH': {88 : 0}, 'MENTHLTH': {88 : 0}})\n",
        "\n",
        "  \"\"\"df = df.replace({'CHOLCHK': {7: 5, 9: 5}}) # cholesterol check\"\"\"  #### does not make sense ..values in data are 1,2,3,9\n",
        "\n",
        "  # Splitting 'group of values' and 'answered/not anwered' options into\n",
        "  # seperate columns\n",
        "  # 88 - None\n",
        "  # 77 - Don't know\n",
        "  # 99 -refused\n",
        "  to_split = ['PHYSHLTH', 'MENTHLTH', 'INCOME2']\n",
        "  for col in to_split:\n",
        "    # for 'PHYSHLTH', 'MENTHLTH' the value is 'days'\n",
        "    # for 'INCOME2' values 1 - 7 represent category of income \n",
        "    # 'Not answered' 0\n",
        "    # 'Answered' 1\n",
        "    df[[f'{col}_VALUE', f'{col}_ANSWERED']] = df.apply(lambda row: (None, 0) if row[col] in [77, 99] else (row[col], 1), axis=1, result_type='expand')\n",
        "\n",
        "  df['INCOME2_VALUE'] = df['INCOME2_VALUE'].apply(lambda x: 9 - x if x != 0 else 0)\n",
        "\n",
        "  df = df.drop(columns=to_split)\n",
        "  # Option for handling missing values; drop all rows with np.nan\n",
        "  df = df.dropna(subset=['DIABETE3'])\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gb0J1hDNUZEq"
      },
      "outputs": [],
      "source": [
        "train_inputs.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lf7oh3PkFo6e"
      },
      "outputs": [],
      "source": [
        "# train_inputs_preprocessed = preprocessing(train_inputs)\n",
        "train_set_preprocessed = preprocessing(train_set)\n",
        "test_set_preprocessed = preprocessing(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdRM4ndbUVoK"
      },
      "outputs": [],
      "source": [
        "# train_inputs_preprocessed.head()\n",
        "train_set_preprocessed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shubqiB6PPTI"
      },
      "outputs": [],
      "source": [
        "# Aby sa mohla pipelina pouzit na rozne modely, trenovacie/testovacie data\n",
        "def get_transform_pipeline():\n",
        "  numerical_features = ['_BMI5', 'PHYSHLTH_VALUE', 'MENTHLTH_VALUE', '_AGEG5YR']\n",
        "  ordinal_features = ['INCOME2_VALUE', 'EDUCA', 'GENHLTH']\n",
        "  # maybe use all of features?:\n",
        "  \"\"\"categorical_features = ['_TOTINDA', '_CHOLCHK', '_FRTLT1', '_VEGLT1', '_RFDRHV5', 'HLTHPLN1', 'MEDCOST', 'GENHLTH', 'INCOME2_ANSWERED', 'PHYSHLTH_ANSWERED', 'MENTHLTH_ANSWERED', '_RFHYPE5', 'TOLDHI2', 'SMOKE100', 'CVDSTRK3', '_RFDRHV5', 'DIFFWALK', 'SEX', '_MICHD']\"\"\"\n",
        "  categorical_features = ['_CHOLCHK']  #### only those with more than 2 answers\n",
        "  return Pipeline([\n",
        "      ('selector', ColumnTransformer([\n",
        "          (\"one-hot\", OneHotEncoder(), categorical_features),\n",
        "          ('ordinal', OrdinalEncoder(), ordinal_features),\n",
        "          ('scaler', MinMaxScaler(feature_range=(0,1)), numerical_features + ordinal_features)\n",
        "      ], remainder='passthrough'))\n",
        "  ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pFVE2Tz1UqO"
      },
      "outputs": [],
      "source": [
        "transform_pipeline = get_transform_pipeline()\n",
        "train_set_transformed = pd.DataFrame(transform_pipeline.fit_transform(train_set_preprocessed))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oQ4zlbLkujt"
      },
      "outputs": [],
      "source": [
        "# train_transformed[train_transformed.columns[30:]].tail()\n",
        "# train_transformed.info()\n",
        "train_set_transformed[train_set_transformed.columns[9:]].tail()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHDyOsHHVz0R"
      },
      "outputs": [],
      "source": [
        "train_set_transformed.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtA6_WKJ3qYw"
      },
      "source": [
        "## Datasety"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Příprava 2 datasetů zmíněných výše."
      ],
      "metadata": {
        "id": "CsWHKYyC3jls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EjaJwVl3qE4"
      },
      "outputs": [],
      "source": [
        "# before 'transforming' function decide what to do with missing values\n",
        "# - in case of skipping nans, you can remove the rows before splitting sets to inputs and targets, then you can transform just inputs\n",
        "# - in case of imputing values, add it to 'transforming' function, because column 'DIABETE3' is not transformed, it should stay as columns[0]\n",
        "## in both cases, create new transforming function and add to pipeline what to do with missing values (add imputers below scaler)\n",
        "\n",
        "# dropped nans\n",
        "train_sp_no_na = train_set_preprocessed.dropna()\n",
        "test_sp_no_na = test_set_preprocessed.dropna()\n",
        "train_X_no_nans, train_y_no_nans = train_sp_no_na.drop(columns=['DIABETE3']), train_sp_no_na['DIABETE3']\n",
        "test_X_no_nans, test_y_no_nans = test_sp_no_na.drop(columns=['DIABETE3']), test_sp_no_na['DIABETE3']\n",
        "\n",
        "# kept nans\n",
        "train_X, train_y = train_set_preprocessed.drop(columns=['DIABETE3']), train_set_preprocessed['DIABETE3']\n",
        "test_X, test_y = test_set_preprocessed.drop(columns=['DIABETE3']), test_set_preprocessed['DIABETE3']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aju1UBiR6jlH"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jako hlavní metriku jsme se rozhodli použít recall, z důvodu charakteru dat, kde je důležité minimalizovat počet *False Negative*. Další metriky, které používáme jsou *rmse, f1_score, precision*."
      ],
      "metadata": {
        "id": "vhOxBZ5A4XBk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EldR15zdNyZg"
      },
      "outputs": [],
      "source": [
        "rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False, squared=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_score(prediction, inputs_y):\n",
        "  print(f\"f1_score: {f1_score(inputs_y, prediction):.4f}  (higher == better)\")\n",
        "  print(f\"rmse: {mean_squared_error(prediction, inputs_y, squared=False):.4f}  (lower == better)\")\n",
        "  print(f\"Precision: {precision_score(inputs_y, prediction):.4f}  (higher == better)\")\n",
        "  print(f\"Recall: {recall_score(inputs_y, prediction):.4f}  (higher == better)\")\n"
      ],
      "metadata": {
        "id": "tQP1t9645Kz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDBFXLWgRpYN"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "# Minimalize FN\n",
        "def display_confusion_matrix(pipeline, test_X, test_y):\n",
        "  sns.reset_orig()\n",
        "  ConfusionMatrixDisplay.from_estimator(\n",
        "      pipeline, test_X, test_y, xticks_rotation=\"vertical\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voj3QVbBCdGD"
      },
      "outputs": [],
      "source": [
        "def visualize(pipeline, train_X, train_y):\n",
        "    scoring_metrics = ['f1', 'neg_mean_squared_error', 'precision', 'recall']\n",
        "    labels = ['F1', 'RMSE', 'Precision', 'Recall']\n",
        "    for i, scoring_metric in enumerate(scoring_metrics):\n",
        "      viz = ValidationCurve(\n",
        "          pipeline,\n",
        "          param_name=\"selectkbest__k\",\n",
        "          param_range=np.arange(2, 22),\n",
        "          cv=10,\n",
        "          scoring=scoring_metric,\n",
        "          title=f'Validaiton curve for {labels[i]} metric'\n",
        "      )\n",
        "      viz.fit(train_X, train_y)\n",
        "      viz.show()\n",
        "      sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modely\n",
        "\n",
        "Jako baseline jsme použili threshold podle BMI. Jako modely jsme zvolili Decision Tree, Random Forest a KNN. Decision tree je dobrá volba pro nevyvážená data, protože se zaměřují na funkce, které jsou nejvhodnější pro rozdělení tříd a jsou relativně jednoduché a snadno interpretovatelné. Random Forest používáme, abychom mohli porovnat s Decision Tree, jelikož oba fungují na stejném základu. Pro KNN jsme se rozhodli, jelikož dobře funguje s nízkodimenzionálními daty, ale na druhou stranu nefunguje moc dobře s nevyrovnané data, takže ta volba byla spíš pro zvědavost.\n",
        "\n"
      ],
      "metadata": {
        "id": "NqF4-TZO60ai"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRNy-7egQeOL"
      },
      "source": [
        "## Baseline\n",
        "\n",
        "Pokud má člověk hodnotu BMI vyšší než 4000, tak vrací, že člověk má Diabetes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOfFDzHXi1Jr"
      },
      "outputs": [],
      "source": [
        "pred_y = test_y.copy()\n",
        "for (index, row) in test_X.iterrows():\n",
        "  if row._BMI5 > 4000:\n",
        "    pred_y[index] = 1\n",
        "  else:\n",
        "    pred_y[index] = 0\n",
        "\n",
        "print_score(pred_y, test_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6W-y24iQZzH"
      },
      "source": [
        "## Decision tree\n",
        "\n",
        "Decision tree je algoritmus strojového učení používaný pro klasifikaci a predikci. Jedná se o stromovou strukturu, ve které každý uzel reprezentuje rozhodování na základě určitého atributu a každá hrana spojuje uzel s jeho potomky. Na základě hodnot atributů vstupních dat se postupně prochází strom a rozhoduje se o klasifikaci nebo predikci cílové proměnné. Při trénování decision tree algoritmus hledá nejlepší atributy pro rozdělení dat a snižuje tak míru nejistoty (entropy) v každém uzlu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu0eXDJuzwys"
      },
      "outputs": [],
      "source": [
        "tree_pipeline1 = Pipeline(\n",
        "    [\n",
        "        (\"transform\", transform_pipeline),\n",
        "        (\"imputer\", SimpleImputer()),\n",
        "        (\"selectkbest\", SelectKBest(score_func=chi2)),\n",
        "        (\"model\", DecisionTreeClassifier())\n",
        "    ])\n",
        "\n",
        "parameters = {\n",
        "    'model__max_depth': [8, 16, 24, 32],\n",
        "    'model__min_samples_leaf': [3, 5, 7, 10, 15],\n",
        "    'selectkbest__k' : [2, 5, 7, 13, 20, 22],\n",
        "    'model__criterion': ['gini', 'entropy'],\n",
        "    'model__max_leaf_nodes': [None, 10, 20, 50],\n",
        "    'model__class_weight': [None, 'balanced']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47U1X0zRj1JL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae32ccce-5cf6-43e0-b605-145b7e376adc"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KEPT NANs\n"
          ]
        }
      ],
      "source": [
        "# Kept nans\n",
        "print('KEPT NANs')\n",
        "\n",
        "gscv_kept = GridSearchCV(tree_pipeline1, parameters, scoring=rmse_scorer)\n",
        "gscv_kept.fit(train_X, train_y)\n",
        "\n",
        "best_model_kept = gscv_kept.best_estimator_\n",
        "prediction_kept = best_model_kept.predict(test_X)\n",
        "\n",
        "print('Best hyperparameters:', gscv_kept.best_params_)\n",
        "print_score(best_model_kept, prediction_kept, test_X, test_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize(\n",
        "    best_model_kept,\n",
        "    train_X,\n",
        "    train_y)"
      ],
      "metadata": {
        "id": "j1iYCIcvHQOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIrc8_8rj2HP"
      },
      "outputs": [],
      "source": [
        "print('Confusion matrix')\n",
        "display_confusion_matrix(best_model_kept, test_X, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TgJ257Nntxn"
      },
      "outputs": [],
      "source": [
        "# Dropped nans\n",
        "tree_pipeline2 = Pipeline(\n",
        "    [\n",
        "        (\"transform\", transform_pipeline),\n",
        "        # (\"imputer\", SimpleImputer()),\n",
        "        (\"selectkbest\", SelectKBest(score_func=chi2)),\n",
        "        (\"model\", DecisionTreeClassifier())\n",
        "    ])\n",
        "\n",
        "print('DROPPED NANs')\n",
        "gscv_dropped = GridSearchCV(tree_pipeline2, parameters, scoring=rmse_scorer)\n",
        "gscv_dropped.fit(train_X_no_nans, train_y_no_nans)\n",
        "\n",
        "best_model_dropped = gscv_dropped.best_estimator_\n",
        "prediction_dropped = best_model_dropped.predict(test_X_no_nans)\n",
        "\n",
        "print('Best hyperparameters:', gscv_dropped.best_params_)\n",
        "print_score(best_model_dropped, prediction_dropped, test_X_no_nans, test_y_no_nans)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize(\n",
        "    best_model_kept,\n",
        "    train_X_no_nans,\n",
        "    train_y_no_nans)"
      ],
      "metadata": {
        "id": "43clLVV7HVR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7yfWHOunyZx"
      },
      "outputs": [],
      "source": [
        "print('Confusion matrix')\n",
        "display_confusion_matrix(best_model_dropped, test_X_no_nans, test_y_no_nans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD-oBYgx08at"
      },
      "source": [
        "## Random Forest\n",
        "\n",
        "Random forest je algoritmus strojového učení, který využívá rozhodovací stromy pro klasifikaci a predikci. Jedná se o soubor stromů, kde každý strom je trénován na náhodně vybrané podmnožině dat a s náhodně vybranými atributy. V průběhu predikce je pak výsledek určen hlasováním mezi výsledky jednotlivých stromů. Tento přístup umožňuje snížit riziko přetrénování, zlepšit přesnost predikce a zvyšovat odolnost algoritmu vůči šumu v datech."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvgZw0sZQIKU"
      },
      "outputs": [],
      "source": [
        "forest_pipeline = Pipeline(\n",
        "    [\n",
        "        (\"transform\", transform_pipeline),\n",
        "        # (\"imputer\", KNNImputer()),\n",
        "        (\"forest\", RandomForestClassifier())\n",
        "    ])\n",
        "\n",
        "forest_pipeline.fit(train_X_no_nans, train_y_no_nans)\n",
        "prediction = forest_pipeline.predict(test_X_no_nans)\n",
        "print_score(prediction, test_y_no_nans)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding best hyperparameters\n",
        "\"\"\"\n",
        "parameters = {'forest__random_state': [42],\n",
        "              # 'forest__criterion': [\"gini\", \"entropy\", \"log_loss\"],\n",
        "              'forest__max_depth': [3, 5, 10, 20, 50],\n",
        "              'forest__min_samples_leaf': [1, 5, 10],\n",
        "              'forest__max_samples': [0.5, 1.0],\n",
        "              'forest__max_features': [\"sqrt\", \"log2\"]\n",
        "              }\n",
        "forest_pipeline_optimized = GridSearchCV(forest_pipeline, parameters, cv=10)\n",
        "forest_pipeline_optimized.fit(train_X_no_nans, train_y_no_nans)\n",
        "\n",
        "print(\"optimized:\")\n",
        "print(f1_score(forest_pipeline_optimized.predict(test_X_no_nans), test_y_no_nans, average=None))\n",
        "\n",
        "print()\n",
        "print(\"best found params:\")\n",
        "\n",
        "forest_pipeline_optimized.best_params_\n",
        "\n",
        "# {'forest__max_depth': 20,\n",
        "#  'forest__max_features': 'log2',\n",
        "#  'forest__max_samples': 1.0,\n",
        "#  'forest__min_samples_leaf': 1,\n",
        "#  'forest__random_state': 42}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "iIzC4XiUFoSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forest_classifier = RandomForestClassifier(max_depth=20, max_features='log2', max_samples=1.0, min_samples_leaf=1, random_state=42)\n",
        "\n",
        "forest_pipeline1 = Pipeline(\n",
        "    [\n",
        "        (\"transform\", transform_pipeline),\n",
        "        (\"forest\", forest_classifier)\n",
        "    ])\n",
        "\n",
        "print(\"dropped nans\")\n",
        "forest_pipeline1.fit(train_X_no_nans, train_y_no_nans)\n",
        "prediction1 = forest_pipeline1.predict(test_X_no_nans)\n",
        "print_score(forest_pipeline, prediction, test_X_no_nans, test_y_no_nans)\n",
        "\n",
        "\n",
        "forest_pipeline2 = Pipeline(\n",
        "    [\n",
        "        (\"transform\", transform_pipeline),\n",
        "        (\"imputer\", KNNImputer()),\n",
        "        (\"forest\", forest_classifier)\n",
        "    ])\n",
        "\n",
        "print()\n",
        "print(\"imputed values\")\n",
        "forest_pipeline2.fit(train_X, train_y)\n",
        "prediction2 = forest_pipeline2.predict(test_X)\n",
        "print_score(forest_pipeline2, prediction2, test_X, test_y)\n",
        "\n"
      ],
      "metadata": {
        "id": "eYmEOqn4FtJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tEi3wo7O26d"
      },
      "source": [
        "## KNN\n",
        "\n",
        "K-Nearest Neighbors (KNN) je algoritmus strojového učení používaný pro klasifikaci a regresi. Algoritmus při klasifikaci přiřazuje novému datovému bodu třídu na základě nejbližších sousedů v trénovacích datech. KNN vyhledává K nejbližších sousedů pomocí eukleidovské vzdálenosti nebo jiné metriky a třídu nového bodu určí podle většiny tříd jeho nejbližších sousedů. Při regresi algoritmus predikuje hodnotu cílové proměnné na základě průměru hodnot nejbližších sousedů. Volbou parametru K lze ovlivnit vliv šumu v datech na predikci."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IxQ0KjmJFhM"
      },
      "outputs": [],
      "source": [
        "scores = []\n",
        "ks = list(range(2, 10))\n",
        "\n",
        "for k in ks:\n",
        "    knn_select_pipeline = make_pipeline(\n",
        "        transform_pipeline,\n",
        "        KNNImputer(),\n",
        "        SelectKBest(k=k),\n",
        "        KNeighborsClassifier(),\n",
        "    )\n",
        "\n",
        "    knn_select_pipeline.fit(train_k_X, train_k_y)\n",
        "    scores.append(knn_select_pipeline.score(validation_X, validation_y))\n",
        "    print(f\"k: {k}, score: {round(scores[-1], 2)}\")\n",
        "\n",
        "print(\"Best score:\", max(scores), \"for k:\", ks[scores.index(max(scores))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owF5wRQ4Me1F"
      },
      "outputs": [],
      "source": [
        "knn_pipeline_1 = make_pipeline(\n",
        "        transform_pipeline,\n",
        "        KNNImputer(),\n",
        "        SelectKBest(k=6),\n",
        "        KNeighborsClassifier(),\n",
        "    )\n",
        "\n",
        "# dataset with umputed NaN values\n",
        "knn_pipeline_1.fit(train_X, train_y)\n",
        "prediction = knn_pipeline_1.predict(test_X)\n",
        "print_score(prediction, test_y)\n",
        "\n",
        "\n",
        "knn_pipeline_2 = make_pipeline(\n",
        "        transform_pipeline,\n",
        "        SelectKBest(k=6),\n",
        "        KNeighborsClassifier(),\n",
        "    )\n",
        "\n",
        "# dataset with dropped NaN values\n",
        "knn_pipeline_2.fit(train_X_no_nans, train_y_no_nans)\n",
        "prediction = knn_pipeline_2.predict(test_X_no_nans)\n",
        "print_score(prediction, test_y_no_nans)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'kneighborsclassifier__n_neighbors': [3, 5, 7],\n",
        "              'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
        "              'kneighborsclassifier__algorithm': ['ball_tree', 'kd_tree', 'auto'],\n",
        "              }\n",
        "                                                    \n",
        "forest_pipeline_optimized = GridSearchCV(knn_pipeline_1, parameters, cv=10, scoring = 'recall')\n",
        "forest_pipeline_optimized.fit(train_X_no_nans, train_y_no_nans)\n",
        "\n",
        "print(\"optimized:\")\n",
        "print(f1_score(forest_pipeline_optimized.predict(train_X_no_nans), train_y_no_nans, average=None))\n",
        "\n",
        "print()\n",
        "print(\"best found params:\")\n",
        "\n",
        "forest_pipeline_optimized.best_params_"
      ],
      "metadata": {
        "id": "9n6Op8UDRRaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_pipeline_1_optimized = make_pipeline(\n",
        "        transform_pipeline,\n",
        "        KNNImputer(),\n",
        "        SelectKBest(k=6),\n",
        "        KNeighborsClassifier(n_neighbors=3, algorithm='kd_tree', weights='distance'),\n",
        "    )\n",
        "\n",
        "# dataset with umputed NaN values\n",
        "knn_pipeline_1_optimized.fit(train_X, train_y)\n",
        "prediction = knn_pipeline_1_optimized.predict(test_X)\n",
        "print_score(prediction, test_y)\n",
        "\n",
        "\n",
        "knn_pipeline_2_optimized = make_pipeline(\n",
        "        transform_pipeline,\n",
        "        SelectKBest(k=6),\n",
        "        KNeighborsClassifier(n_neighbors=3, algorithm='kd_tree', weights='distance'),\n",
        "    )\n",
        "\n",
        "# dataset with dropped NaN values\n",
        "knn_pipeline_2_optimized.fit(train_X_no_nans, train_y_no_nans)\n",
        "prediction = knn_pipeline_2_optimized.predict(test_X_no_nans)\n",
        "print_score(prediction, test_y_no_nans)"
      ],
      "metadata": {
        "id": "toSovagmLi3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1w45UUq31omf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finální vyhodnocení"
      ],
      "metadata": {
        "id": "8HkIu5cN-nU1"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MBCHhzi-kolt"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}